{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a62116b6-c67f-4284-93fd-c2323a2691dc",
   "metadata": {},
   "source": [
    "# Parameters Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e130ab48-6e10-4c4c-b6b2-df1e310397fe",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31553806-2324-43d0-bd0e-f9e8bea52a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests         # Used to make HTTP requests to the Redash API.\n",
    "import pandas as pd     # Provides data structures and data analysis tools (e.g., DataFrame).\n",
    "import smtplib          # Enables sending emails using the Simple Mail Transfer Protocol (SMTP).\n",
    "from email.mime.multipart import MIMEMultipart   # For creating multipart MIME messages.\n",
    "from email.mime.text import MIMEText             # For creating MIME objects of major type text.\n",
    "import time\n",
    "from time import sleep  # Allows us to pause execution of the script for a specified amount of time.\n",
    "import io\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import smtplib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773a3d98-43fc-4bab-b3af-c6780912b31e",
   "metadata": {},
   "source": [
    "## API Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c684cf9d-54fb-4e31-b7b4-295920ed1f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redash API configuration\n",
    "api_url = 'http://10.20.32.6:5000/api' # The base URL where the Redash server is accessible.\n",
    "api_key = 'fpSflr67pifLS1WVyhOtyciUeeRVcp7t8zfZnx3D'  # API key for authenticating the requests.\n",
    "query_ids = [53, 54, 55, 56]  # List of Query IDs that you want to execute and fetch data from.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66447b7-871b-4b21-9bed-9438b634a454",
   "metadata": {},
   "source": [
    "### With these configurations in place, you can proceed to write the functions or scripts to interact with the Redash API, process the fetched data, and send it through email as needed. Each section's functionality can be encapsulated in functions for better modularity and reusability of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0d7e25-97b6-406a-b1f2-07ffa8079d6a",
   "metadata": {},
   "source": [
    "## Preceeding towards execution of Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a24fba-8dc0-4a23-a77d-860a2567370b",
   "metadata": {},
   "source": [
    "## Complete Script to Execute and Retrieve Data from Redash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6062dcd-66ee-48f8-b434-6e59ef08e187",
   "metadata": {},
   "source": [
    "### Step 1: Define Function to Execute and Refresh a Query\n",
    "This function sends a POST request to trigger the execution of a Redash query. This is necessary when you want to ensure that the data you retrieve is the most recent data available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb7a058-63b4-461e-bae4-180669c4d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_redash_query(query_id):\n",
    "    \"\"\"Initiate execution of a Redash query and return the job information.\"\"\"\n",
    "    execution_url = f\"{api_url}/queries/{query_id}/refresh\"\n",
    "    headers = {\n",
    "        'Authorization': f\"Key {api_key}\",\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    response = requests.post(execution_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        job = response.json()['job']\n",
    "        print(f\"Query {query_id} execution triggered successfully, job ID: {job['id']}\")\n",
    "        return job\n",
    "    else:\n",
    "        print(f\"Failed to trigger execution for query {query_id}. Status code: {response.status_code}\")\n",
    "        print(f\"Error response: {response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61bb1f48-a8c7-4a8b-8d8b-7e8ef509cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_query_status(job_id):\n",
    "    \"\"\"Poll the status of a query execution until completion.\"\"\"\n",
    "    status_url = f\"{api_url}/jobs/{job_id}\"\n",
    "    headers = {'Authorization': f'Key {api_key}'}\n",
    "    while True:\n",
    "        response = requests.get(status_url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            status = response.json()['job']['status']\n",
    "            if status == 3:  # Status 3 means the query execution has completed successfully\n",
    "                print(\"Query execution completed successfully.\")\n",
    "                return True\n",
    "            elif status == 4:  # Status 4 means the query execution has failed\n",
    "                print(\"Query execution failed.\")\n",
    "                return False\n",
    "        else:\n",
    "            print(f\"Failed to check status for job {job_id}. Status code: {response.status_code}\")\n",
    "            return False\n",
    "        time.sleep(5)  # Wait for a short period before polling again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13ed3d7-39c3-461b-8951-3e19e4741827",
   "metadata": {},
   "source": [
    "### Step 2: Define Function to Retrieve Query Results\n",
    "After triggering the query execution, this function fetches the results. It's important to ensure the query has finished executing before calling this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f91a1df-343c-4211-98d8-35aae7a65258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_query_results(query_id):\n",
    "    \"\"\"Fetch the results of a completed query execution.\"\"\"\n",
    "    headers = {'Authorization': f'Key {api_key}'}\n",
    "    results_url = f\"{api_url}/queries/{query_id}/results.json\"\n",
    "    response = requests.get(results_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        df = pd.DataFrame(data['query_result']['data']['rows'])\n",
    "        print(f\"Results fetched successfully for query ID {query_id}.\")\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Failed to fetch results for query ID {query_id}. Status code: {response.status_code}\")\n",
    "        print(f\"Error response: {response.text}\")\n",
    "        raise Exception(f\"Failed to fetch results. Response: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e7084-650b-409d-b50f-35bcfd5eda08",
   "metadata": {},
   "source": [
    "### Fetching and Assigning\n",
    "Define Query IDs: A list named query_ids is created containing four integers: 53, 54, 55, and 56. These numbers represent specific query identifiers that will be used to fetch data from a database or a service like Redash.\n",
    "\n",
    "Initialize an Empty Dictionary: A dictionary named dfs is initialized to store the results of each query. Each query's results will later be assigned to this dictionary with keys formatted as 'df' followed by the query ID (e.g., 'df53').\n",
    "\n",
    "Loop Over Query IDs: A for loop is initiated to process each query ID in the query_ids list one by one.\n",
    "Print Status Message: For each query ID, a message is printed to indicate that the processing of that particular query ID is starting.\n",
    "\n",
    "Execute Query: The function execute_redash_query(query_id) is called with the current query ID. This function is responsible for triggering the execution of the query on the Redash server.\n",
    "\n",
    "Wait for Completion: The code then pauses for 10 seconds using sleep(10). This delay is intended to give enough time for the query to complete its execution on the server before the results are fetched.\n",
    "\n",
    "Fetch Query Results: After the wait, the fetch_query_results(query_id) function is called to retrieve the results of the executed query and store them in the variable df.\n",
    "\n",
    "Assign DataFrames to Specific Variables: In the final step, the DataFrames stored in the dictionary are unpacked into individual variables df53, df54, df55, and df56. This is done using a generator expression (dfs[f'df{query_id}'] for query_id in query_ids) which iterates over the same list of query IDs and fetches each corresponding DataFrame from the dfs dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4a8f736-06e5-4bd4-a00e-873f52b5859e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing query ID 53...\n",
      "Query 53 execution triggered successfully, job ID: e87ffd42-3f09-48df-b429-87eefc270248\n",
      "Query execution completed successfully.\n",
      "Results fetched successfully for query ID 53.\n",
      "Processing query ID 54...\n",
      "Query 54 execution triggered successfully, job ID: fa662ca7-d45d-47f9-8cb0-e901ea2a2b54\n",
      "Query execution completed successfully.\n",
      "Results fetched successfully for query ID 54.\n",
      "Processing query ID 55...\n",
      "Query 55 execution triggered successfully, job ID: 9fa798d3-c2f7-4efb-a334-34bd76130126\n",
      "Query execution completed successfully.\n",
      "Results fetched successfully for query ID 55.\n",
      "Processing query ID 56...\n",
      "Query 56 execution triggered successfully, job ID: 5c880e33-e7d9-4e86-9236-9df508d00059\n",
      "Query execution completed successfully.\n",
      "Results fetched successfully for query ID 56.\n"
     ]
    }
   ],
   "source": [
    "# Main execution loop\n",
    "dfs = {}\n",
    "for query_id in query_ids:\n",
    "    print(f\"Processing query ID {query_id}...\")\n",
    "    job_info = execute_redash_query(query_id)\n",
    "    if job_info and check_query_status(job_info['id']):\n",
    "        df = fetch_query_results(query_id)\n",
    "        dfs[f'df{query_id}'] = df\n",
    "\n",
    "# Assign DataFrames to explicit variables\n",
    "df53, df54, df55, df56 = (dfs[f'df{query_id}'] for query_id in query_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cf920b-661e-482f-a7d7-0c8288dfd03f",
   "metadata": {},
   "source": [
    "## Reading an External File to Categorize Clinic Names as Internal, External, or Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18d44e9c-f73e-472a-b5ab-54fadff6c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQW0rTtOgAX7cAXkO-eY5GB8AkPhs2Org5HvE2X-dACf0NjrHHXnuR8cVUCST7xA5luqu_8uS3KSEho/pub?output=csv'\n",
    "df1 = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2c338a-406f-47e8-81df-6d35b659d64d",
   "metadata": {},
   "source": [
    "### Renaming Clinic Names to Align with Required Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75b8a705-9ae4-4bfc-b33a-95a9524bbbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rename(columns={'Clinic_Name': 'Clinic Name'}, inplace=True)\n",
    "df53.rename(columns={'Clinic_Name': 'Clinic Name'}, inplace=True)\n",
    "df54.rename(columns={'Clinic_Name': 'Clinic Name'}, inplace=True)\n",
    "df55.rename(columns={'Clinic_Name': 'Clinic Name'}, inplace=True)\n",
    "df56.rename(columns={'Clinic_Name': 'Clinic Name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c50b67-eb88-4ebb-9691-5a762457c425",
   "metadata": {},
   "source": [
    "### Merging Data and Assigning the Result to a New DataFrame\n",
    "\n",
    "Initialize the Base DataFrame: The DataFrame df2 is initialized by setting it equal to df1. This makes df2 the starting point or base DataFrame for subsequent merging operations.\n",
    "\n",
    "Define List of DataFrames for Merging: A list named other_dfs is created containing DataFrames df53, df54, df55, and df56. These are the DataFrames that will be merged into the base DataFrame df2.\n",
    "\n",
    "Merge DataFrames in a Loop:\n",
    "The code enters a loop that iterates over each DataFrame in the other_dfs list.\n",
    "\n",
    "Inside the loop, the pd.merge() function is used to merge df2 with the current DataFrame (df) from the list. The merging is based on the column \"Clinic Name\", ensuring that rows with the same clinic name in both DataFrames are aligned together.\n",
    "\n",
    "The how=\"outer\" parameter is specified, which means the merge will include all rows from both df2 and the current DataFrame df, even if they do not have matching entries in the \"Clinic Name\" column. This results in a union of all entries, filling in missing data with NaNs where no match is found.\n",
    "\n",
    "The result of each merge is assigned back to df2, updating it with the combined data from the merge operation.\n",
    "\n",
    "This code sequentially merges multiple DataFrames (df53, df54, df55, df56) into a base DataFrame (df1) based on matching clinic names, using an outer join to ensure all data from all DataFrames is retained. The resulting merged DataFrame (df2) contains a comprehensive dataset with entries from all involved DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f058c7e-1cfd-4484-9a13-6a94b7d6eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with df1 as the base for merging\n",
    "df2 = df1\n",
    "\n",
    "# List of other DataFrames to merge\n",
    "other_dfs = [df53, df54, df55, df56]\n",
    "\n",
    "# Merge each DataFrame into df2\n",
    "for df in other_dfs:\n",
    "    df2 = pd.merge(df2, df, on=\"Clinic Name\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f94d86c-5812-409f-8a44-468ba04c5a50",
   "metadata": {},
   "source": [
    "### Replacing All Unknown or NaN Values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69e18a6d-8bc2-4c9b-8625-5910d4523ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284dd80c-2553-4168-a67c-c15d527b131b",
   "metadata": {},
   "source": [
    "### Removing Clinics Not Categorized as External or Internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d3427e-8a25-47b2-b9e3-624df51d87d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where 'External / Internal' is 0\n",
    "df2 = df2[df2['External / Internal'] != 0]\n",
    "\n",
    "# Optional: Reset the index if you want a clean index after removing rows\n",
    "df2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463a10c8-a21c-4e45-827e-b39244e7e796",
   "metadata": {},
   "source": [
    "### Rearranging and Renaming Columns According to Specified Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95b54b27-ee69-4b3a-ac05-43d38337bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new column names as a dictionary\n",
    "new_column_names = {\n",
    "    'Clinic_Staff_Count': '#Staff Count',\n",
    "    'lastLoginAt': 'Last login date',\n",
    "    'loggedIn7Days': 'Last Login in past 7 days?',\n",
    "    'loggedIn30Days': 'Last Login in past 30 days?',\n",
    "    'Total Patients': '#Total Patients',\n",
    "    'Patients added in last 30 days': '#Patients added in last 30 days',\n",
    "    'Patients added in last 7 days': '#Patients added in last 7 days',\n",
    "    'Meetings_Attended': '#Total meetings',\n",
    "    'Meetings_Completed': '#Meetings Completed',\n",
    "    '%Completion_of_Meetings': '%Completion Rate',\n",
    "    'Proprietary_Supplements_Count': '#Proprietary Supplements Count'\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "df2.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "# Define the new order of the columns, excluding the removed column\n",
    "column_order = [\n",
    "    'Clinic Name',\n",
    "    'External / Internal',\n",
    "    '#Staff Count',\n",
    "    'Last login date',\n",
    "    'Last Login in past 7 days?',\n",
    "    'Last Login in past 30 days?',\n",
    "    '#Total Patients',\n",
    "    '#Patients added in last 30 days',\n",
    "    '#Patients added in last 7 days',\n",
    "    '#Total meetings',\n",
    "    '#Meetings Completed',\n",
    "    '%Completion Rate',\n",
    "    '#Proprietary Supplements Count'\n",
    "]\n",
    "\n",
    "# Reorder the columns in df2\n",
    "df2 = df2[column_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b3b3ea-9513-4852-b3fc-96d8b9b14d4b",
   "metadata": {},
   "source": [
    "### Replacing All Unknown or NaN Values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecbf4fd5-6191-4cda-b7d0-5d8b3bc4af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to update\n",
    "columns_to_update = ['Last login date', 'Last Login in past 7 days?', 'Last Login in past 30 days?']\n",
    "\n",
    "# Replace '0' with '-' in these columns\n",
    "df2[columns_to_update] = df2[columns_to_update].replace({0: '-'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88a8ce-a816-436c-a3bb-c233510ac9ac",
   "metadata": {},
   "source": [
    "### Creating and processing a pivot table in pandas:\n",
    "\n",
    "1. **Import Libraries**:\n",
    "   - Import `numpy` and `pandas` libraries, which are fundamental for data manipulation in Python. `numpy` is typically used for numerical operations.\n",
    "\n",
    "2. **Creating the Pivot Table**:\n",
    "   - `df3 = df2.pivot_table(...)`: Create a pivot table from `df2`. A pivot table is a summarized table used for data analysis.\n",
    "   - `index='External / Internal'`: Set the index of the pivot table to the 'External / Internal' column to group data based on these categories.\n",
    "   - `values=[...]`: Define the columns to be included in the pivot table. These columns will have aggregation functions applied as defined in `aggfunc`.\n",
    "   - `aggfunc={...}`: Assign specific aggregation functions to each column:\n",
    "     - `'Clinic Name': pd.Series.nunique`: Count unique values in the 'Clinic Name' column.\n",
    "     - All other specified columns (`'#Staff'`, `'#Patients'`, etc.): Sum up the values using `np.sum`.\n",
    "   - `margins=True`: Include a 'Grand Total' row at the end of the pivot table that provides the overall sum for each column.\n",
    "   - `margins_name='Grand Total'`: Set the name for the total row.\n",
    "\n",
    "3. **Calculate %Completion of Meetings**:\n",
    "   - `df3['%Completion of Meetings']`: Calculate the percentage of meetings completed by dividing the '#Meetings Completed' by '#Total meetings', replacing NaN values with 0.\n",
    "   - `.apply(lambda x: f\"{x:.0%}\")`: Format the result as a percentage with no decimal places.\n",
    "\n",
    "4. **Rename Columns**:\n",
    "   - `df3.rename(columns={'Clinic Name': '#Clinic Count'}, inplace=True)`: Rename the 'Clinic Name' column in `df3` to '#Clinic Count' to better reflect that it represents a count of unique clinic names.\n",
    "\n",
    "5. **Ensure Correct Column Order**:\n",
    "   - `column_order = [...]`: Define a specific order for the columns.\n",
    "   - `df3 = df3[column_order]`: Reorder the columns in `df3` according to the list `column_order` to ensure the data is presented in a logical and consistent format.\n",
    "\n",
    "**Summary**: The code constructs a pivot table from an existing DataFrame, applies specific aggregation functions, calculates additional metrics, and formats the table with precise naming and ordering to enhance readability and utility for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4803ae51-7930-48c1-a4da-c6416d657244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_4048\\1405056759.py:2: FutureWarning: The provided callable <function sum at 0x000002767FA55EE0> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  df3 = df2.pivot_table(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Affiliate Category</th>\n",
       "      <th>#Clinic Count</th>\n",
       "      <th>#Staff Count</th>\n",
       "      <th>#Proprietary Supplements Count</th>\n",
       "      <th>#Total Patients</th>\n",
       "      <th>#Patients added in last 30 days</th>\n",
       "      <th>#Patients added in last 7 days</th>\n",
       "      <th>#Total meetings</th>\n",
       "      <th>#Meetings Completed</th>\n",
       "      <th>%Completion of Meetings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>External</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Internal Healthcare Team</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>668</td>\n",
       "      <td>782</td>\n",
       "      <td>76</td>\n",
       "      <td>22</td>\n",
       "      <td>628</td>\n",
       "      <td>196</td>\n",
       "      <td>31%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non-Healthcare (Tech / Test accounts)</td>\n",
       "      <td>20</td>\n",
       "      <td>151</td>\n",
       "      <td>153</td>\n",
       "      <td>402</td>\n",
       "      <td>76</td>\n",
       "      <td>20</td>\n",
       "      <td>800</td>\n",
       "      <td>273</td>\n",
       "      <td>34%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grand Total</td>\n",
       "      <td>60</td>\n",
       "      <td>208</td>\n",
       "      <td>823</td>\n",
       "      <td>1271</td>\n",
       "      <td>156</td>\n",
       "      <td>42</td>\n",
       "      <td>1470</td>\n",
       "      <td>472</td>\n",
       "      <td>32%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Affiliate Category  #Clinic Count  #Staff Count  \\\n",
       "0                               External             15            22   \n",
       "1               Internal Healthcare Team             25            35   \n",
       "2  Non-Healthcare (Tech / Test accounts)             20           151   \n",
       "3                            Grand Total             60           208   \n",
       "\n",
       "   #Proprietary Supplements Count  #Total Patients  \\\n",
       "0                               2               87   \n",
       "1                             668              782   \n",
       "2                             153              402   \n",
       "3                             823             1271   \n",
       "\n",
       "   #Patients added in last 30 days  #Patients added in last 7 days  \\\n",
       "0                                4                               0   \n",
       "1                               76                              22   \n",
       "2                               76                              20   \n",
       "3                              156                              42   \n",
       "\n",
       "   #Total meetings  #Meetings Completed %Completion of Meetings  \n",
       "0               42                    3                      7%  \n",
       "1              628                  196                     31%  \n",
       "2              800                  273                     34%  \n",
       "3             1470                  472                     32%  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the pivot table\n",
    "df3 = df2.pivot_table(\n",
    "    index='External / Internal',\n",
    "    values=[\n",
    "        'Clinic Name', '#Staff Count', '#Patients added in last 30 days', '#Patients added in last 7 days',\n",
    "        '#Total Patients', '#Total meetings', '#Meetings Completed', '#Proprietary Supplements Count'\n",
    "    ],\n",
    "    aggfunc={\n",
    "        'Clinic Name': pd.Series.nunique,  # Counts unique clinic names as '#Clinic Count'\n",
    "        '#Staff Count': np.sum,\n",
    "        '#Patients added in last 30 days': np.sum,\n",
    "        '#Patients added in last 7 days': np.sum,\n",
    "        '#Total Patients': np.sum,\n",
    "        '#Total meetings': np.sum,\n",
    "        '#Meetings Completed': np.sum,\n",
    "        '#Proprietary Supplements Count': np.sum\n",
    "    },\n",
    "    margins=True,\n",
    "    margins_name='Grand Total'\n",
    ")\n",
    "\n",
    "# Calculate %Completion of Meetings\n",
    "df3['%Completion of Meetings'] = (df3['#Meetings Completed'] / df3['#Total meetings']).fillna(0).apply(lambda x: f\"{x:.0%}\")\n",
    "\n",
    "# Rename the 'Clinic Name' to '#Clinic Count'\n",
    "df3.rename(columns={'Clinic Name': '#Clinic Count'}, inplace=True)\n",
    "\n",
    "# Ensure the correct column order before resetting index\n",
    "column_order = [\n",
    "    '#Clinic Count', '#Staff Count', '#Patients added in last 30 days', \n",
    "    '#Patients added in last 7 days', '#Total Patients', '#Total meetings', \n",
    "    '#Meetings Completed', '%Completion of Meetings', '#Proprietary Supplements Count'\n",
    "]\n",
    "df3 = df3[column_order]\n",
    "\n",
    "# Reset the index to turn the 'External / Internal' index into a regular column\n",
    "df3.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns appropriately\n",
    "df3.rename(columns={'External / Internal': 'Affiliate Category'}, inplace=True)\n",
    "\n",
    "# Reorder the DataFrame to ensure 'Affiliate Category' is the first column\n",
    "df3 = df3[['Affiliate Category', '#Clinic Count', '#Staff Count', '#Proprietary Supplements Count', \n",
    "           '#Total Patients', '#Patients added in last 30 days', '#Patients added in last 7 days', \n",
    "           '#Total meetings', '#Meetings Completed', '%Completion of Meetings']]\n",
    "\n",
    "# Convert numerical columns to integers to remove the decimal points\n",
    "numeric_columns = ['#Clinic Count', '#Staff Count', '#Proprietary Supplements Count', '#Total Patients', \n",
    "                   '#Patients added in last 30 days', '#Patients added in last 7 days', \n",
    "                   '#Total meetings', '#Meetings Completed']\n",
    "df3[numeric_columns] = df3[numeric_columns].astype(int)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360c6647-8470-4ed2-a38c-e124ca13f314",
   "metadata": {},
   "source": [
    "### Modifying df3\n",
    "\n",
    "1. **Resetting the Index**:\n",
    "   - `df3.reset_index(inplace=True)`: This line converts the index of the DataFrame `df3` into a regular column. Since 'External / Internal' is set as an index, this action transforms it back into a standard column within the DataFrame. The `inplace=True` parameter modifies the DataFrame directly, saving the need to reassign it.\n",
    "\n",
    "2. **Renaming Columns**:\n",
    "   - `df3.rename(columns={'External / Internal': 'Affiliate Type - External / Internal'}, inplace=True)`: This changes the name of the 'External / Internal' column to 'Affiliate Type - External / Internal' for clearer identification. Again, `inplace=True` ensures the DataFrame is updated directly.\n",
    "\n",
    "3. **Dropping Unwanted Rows**:\n",
    "   - This step involves conditional logic to remove unwanted rows based on specific criteria. The condition `if df3.iloc[1, 0] == 'Unwanted Row Identifier'` checks if the first column of the second row (indexed at 1) matches 'Unwanted Row Identifier'. If it does, that row is removed using `df3.drop(index=1, inplace=True)`. This function deletes the row at index 1 and modifies the DataFrame in place.\n",
    "\n",
    "4. **Reordering the DataFrame**:\n",
    "   - The last line rearranges the columns of `df3` into a specified order, ensuring that 'Affiliate Type - External / Internal' appears first. The list provided in the brackets specifies the new order of the columns, and the DataFrame is reassigned to `df3` with these columns reordered accordingly.\n",
    "\n",
    "**Summary**: The code modifies the DataFrame `df3` by resetting its index, renaming a column for clarity, optionally removing an unwanted row based on a specific condition, and reordering the columns to ensure logical presentation. These steps are typically used to clean and organize data for better analysis and reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c526832e-e63e-40c4-b7c7-142d3bab7ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for external clinics and select relevant columns\n",
    "df56a = df2[df2['External / Internal'] == 'External'][[\n",
    "    'Clinic Name', 'External / Internal', 'Last login date', \n",
    "    'Last Login in past 7 days?', 'Last Login in past 30 days?'\n",
    "]]\n",
    "\n",
    "# Rename 'Clinic Name' to 'Affiliate Name'\n",
    "df56a.rename(columns={'Clinic Name': 'Affiliate Name'}, inplace=True)\n",
    "\n",
    "# Modify 'Last login date' to display only the date\n",
    "df56a['Last login date'] = pd.to_datetime(df56a['Last login date'], errors='coerce').dt.date\n",
    "\n",
    "# Replace NaT values with '-'\n",
    "df56a['Last login date'] = df56a['Last login date'].apply(lambda x: '-' if pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7355b15e-1db4-47e2-a2b1-8412962e4d0d",
   "metadata": {},
   "source": [
    "### Email creation and sending with HTML content and CSV attachments:\n",
    "\n",
    "1. **Define Conversion Function**:\n",
    "   - `dataframe_to_email_attachment(df, filename)`: Defines a function to convert a pandas DataFrame into a MIMEApplication object suitable for email attachments. It:\n",
    "     - Creates a CSV from the DataFrame using `StringIO`, which acts like a file held in memory.\n",
    "     - Sets the file's name within the MIME object and its content disposition, facilitating its use as an attachment in emails.\n",
    "   \n",
    "2. **Convert DataFrames to HTML**:\n",
    "   - `html_content_df3 = df3.to_html(index=False)`: Converts the DataFrame `df3` to HTML format for embedding directly into the email. `index=False` prevents the index from being included in the HTML table.\n",
    "   - `html_content_df56 = df56.to_html(index=False)`: Similar conversion for DataFrame `df56`.\n",
    "\n",
    "3. **Combine HTML Content**:\n",
    "   - `combined_html`: Combines the HTML representations of the two DataFrames with headings into a single HTML string. This will be the body of the email.\n",
    "\n",
    "4. **Create Filename and Attachments**:\n",
    "   - `today_date`: Gets the current date formatted as 'YYYY-MM-DD'.\n",
    "   - `filename_df3` and `filename_df56`: Constructs filenames for the CSV files incorporating the date.\n",
    "   - `attachment_df3` and `attachment_df56`: Converts `df3` and `df56` to MIMEApplication objects using the previously defined function.\n",
    "\n",
    "5. **Setup Email**:\n",
    "   - `message = MIMEMultipart()`: Starts assembling a multipart email message that can include both HTML content and file attachments.\n",
    "   - Sets the 'From', 'To', and 'Subject' fields of the email.\n",
    "   - Attaches the combined HTML content and both CSV files to the email message.\n",
    "\n",
    "6. **Send Email via SMTP**:\n",
    "   - Establishes an SSL connection to the SMTP server on the given port.\n",
    "   - Logs in to the server using the provided email credentials.\n",
    "   - Sends the prepared email message.\n",
    "   - Catches and prints any errors during the sending process, which helps in troubleshooting.\n",
    "\n",
    "7. **Print Confirmation or Error Message**:\n",
    "   - Outputs a confirmation if the email was sent successfully or details of any error that occurred, providing feedback on the operation's result.\n",
    "\n",
    "**Summary**: This script automates the process of sending a detailed email report, which includes both visual (HTML) and downloadable (CSV) data summaries, by programmatically converting data frames, creating email content, attaching files, and handling SMTP email sending, all encapsulated in a structured and error-handling script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "589abd48-353e-4bda-b577-ce1ffc9d9668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email configuration\n",
    "sender_email = \"yash.kumar@lybl.com\"         # The email address from which the report will be sent.\n",
    "sender_password = \"OnePlux@1972\"             # Password for the sender's email account.\n",
    "receiver_emails = \"yash.kumar@lybl.com\"  # List of recipient email addresses.\n",
    "smtp_server = \"smtp.gmail.com\"               # The SMTP server through which emails will be sent.\n",
    "smtp_port = 465  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6fd193b-ec0d-4cff-a7d1-e18c88b59019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email sent successfully with detailed HTML content and CSV attachments.\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from datetime import datetime, timedelta\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "import smtplib\n",
    "\n",
    "# Custom function to format date without ordinal suffix\n",
    "def format_date(date):\n",
    "    return date.strftime(\"%d %B '%y\")\n",
    "\n",
    "# Get yesterday's date and format it\n",
    "yesterday_date = datetime.now() - timedelta(days=1)\n",
    "formatted_yesterday_date = format_date(yesterday_date)\n",
    "\n",
    "# Function to convert DataFrame to MIMEApplication object\n",
    "def dataframe_to_email_attachment(df, filename):\n",
    "    \"\"\"Convert DataFrame to MIMEApplication object for email attachment.\"\"\"\n",
    "    csv_buffer = io.StringIO()\n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "    csv_buffer.seek(0)\n",
    "    mime_object = MIMEApplication(csv_buffer.read(), Name=filename)\n",
    "    mime_object['Content-Disposition'] = f'attachment; filename=\"{filename}\"'\n",
    "    return mime_object\n",
    "\n",
    "# Calculate summary statistics\n",
    "external_affiliates = df2[df2['External / Internal'] == 'External']\n",
    "n = external_affiliates['Clinic Name'].nunique()\n",
    "p = int(external_affiliates['#Staff Count'].sum())\n",
    "q = int(external_affiliates['#Total Patients'].sum())\n",
    "r = int(external_affiliates['#Total meetings'].sum())\n",
    "s = int(external_affiliates['#Proprietary Supplements Count'].sum())\n",
    "x = int(external_affiliates['#Patients added in last 30 days'].sum())\n",
    "y = int(external_affiliates['#Patients added in last 7 days'].sum())\n",
    "\n",
    "# Convert DataFrames to HTML for email content\n",
    "html_content_df3 = df3.to_html(index=False, classes=\"dataframe\")\n",
    "html_content_df56a = df56a.to_html(index=False, classes=\"dataframe\")\n",
    "\n",
    "# Adding inline styles to ensure the first column and header row are left-aligned\n",
    "def add_inline_styles(html_content):\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Left-align all header cells\n",
    "    for th in soup.find_all('th'):\n",
    "        th['style'] = 'text-align: left;'\n",
    "    \n",
    "    # Left-align first column cells\n",
    "    for row in soup.find_all('tr'):\n",
    "        first_td = row.find('td')\n",
    "        if first_td:\n",
    "            first_td['style'] = 'text-align: left;'\n",
    "    \n",
    "    return str(soup)\n",
    "\n",
    "html_content_df3 = add_inline_styles(html_content_df3)\n",
    "html_content_df56a = add_inline_styles(html_content_df56a)\n",
    "\n",
    "# Styling for the tables\n",
    "style = \"\"\"\n",
    "<style>\n",
    "    .dataframe {\n",
    "        width: 100%;\n",
    "        border-collapse: collapse;\n",
    "        table-layout: fixed; /* Ensures each column has equal width */\n",
    "    }\n",
    "    .dataframe th, .dataframe td {\n",
    "        border: 1px solid #ddd;\n",
    "        padding: 8px;\n",
    "        text-align: center; /* Centers text by default */\n",
    "    }\n",
    "    .dataframe th:first-child, .dataframe td:first-child {\n",
    "        text-align: left; /* Left-aligns the first column and header cells */\n",
    "    }\n",
    "    .dataframe thead th {\n",
    "        background-color: #f2f2f2;\n",
    "        color: black;\n",
    "    }\n",
    "    .dataframe tfoot th {\n",
    "        background-color: #f9f9f9;\n",
    "    }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "# Create attachments with formatted yesterday's date\n",
    "filename_df3 = f\"Production_Summary_{formatted_yesterday_date}.csv\"\n",
    "filename_df56a = f\"External_Affiliate_Login_Details_{formatted_yesterday_date}.csv\"\n",
    "attachment_df3 = dataframe_to_email_attachment(df3, filename_df3)\n",
    "attachment_df56a = dataframe_to_email_attachment(df56a, filename_df56a)\n",
    "\n",
    "# Email body content setup\n",
    "email_subject = f\"LYBL Platform Usage Weekly Report (Affiliates) | {formatted_yesterday_date}\"\n",
    "email_body = f\"\"\"\n",
    "<html>\n",
    "<head>\n",
    "{style}\n",
    "</head>\n",
    "<body>\n",
    "<p>Hi Team,</p>\n",
    "<p>Please find the latest usage analytics (affiliates) updated as on {formatted_yesterday_date}.</p>\n",
    "\n",
    "<h3>How to read this report?</h3>\n",
    "<p><b>High level platform usage</b></p>\n",
    "<p>The ‘{n}’ external affiliates together have added ‘{p}’ staffs, ‘{q}’ patients, ‘{r}’ meetings and ‘{s}’ proprietary supplements.</p>\n",
    "<p><b>Daily / monthly level platform usage</b></p>\n",
    "<p>The ‘{n}’ external affiliates have added ‘{x}’ patients in the last 30 days and ‘{y}’ patients in the last 7 days.</p>\n",
    "<p>The ‘{n}’ external affiliates login information (whether they logged in the app in the last 7 days/ 30 days) is available below.</p>\n",
    "\n",
    "<h3>Production Data</h3>\n",
    "{html_content_df3}\n",
    "<h3>External Affiliate Login Details with 7 days and 30 days Info</h3>\n",
    "{html_content_df56a}\n",
    "<p>Please find the raw data attached as CSV.</p>\n",
    "<p>Thank You,</p>\n",
    "<p>Yash Kumar</p>\n",
    "<p>Data Analytics Intern</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Setup and send the email\n",
    "message = MIMEMultipart()\n",
    "message['From'] = sender_email\n",
    "message['To'] = receiver_emails\n",
    "message['Subject'] = email_subject\n",
    "message.attach(MIMEText(email_body, 'html'))  # Attach HTML content\n",
    "message.attach(attachment_df3)  # Attach df3 CSV\n",
    "message.attach(attachment_df56a)  # Attach df56a CSV\n",
    "\n",
    "# Send the email using SMTP\n",
    "try:\n",
    "    with smtplib.SMTP_SSL(smtp_server, smtp_port) as server:\n",
    "        server.login(sender_email, sender_password)\n",
    "        server.send_message(message)\n",
    "    print(\"Email sent successfully with detailed HTML content and CSV attachments.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while sending the email: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19609ada-e91b-4c48-9314-1c040262bca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aa6c1f-7cd6-4487-8074-e7ddc4f7484a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c459891-90b9-4d58-8eab-8e1e7eb7e371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6722e7bd-595b-4861-a9a2-b7ff76818b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f4bc91-333d-4076-91ed-a3491173b193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13123874-1070-4779-a1ee-799cee3e32d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad51a6c-99ae-47e7-bf7b-9f4d88c172de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c8e9c5-c035-4cce-8be9-758ded84298f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ea5e7c-5d45-46c7-bbfd-c87521410e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a56f99d-ab12-4bff-98cb-f843a21f3996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
